{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"801286efa5be2fd2e34fbf88c833cfc87ea2a74cca93799cc699da713e1f54d5"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets tokenizers huggingface -q\n!pip install datasets evaluate transformers[sentencepiece] -q\n!apt install git-lfs -q\n!pip install py7zr -q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GutfoB-pzGw-","outputId":"26619ad6-b771-4902-eb6c-3a2037b18a93","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport torch\nfrom transformers import AutoModelForMaskedLM,LongformerModel\nfrom transformers import AutoTokenizer\nfrom transformers import DataCollatorForLanguageModeling\nfrom tqdm import tqdm\nfrom datasets import Dataset\nimport warnings\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset,DatasetDict\nfrom datasets import load_dataset\nimport pandas as pd\nfrom datasets import load_dataset","metadata":{"colab":{"background_save":true},"id":"y0gES_06zZC7","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n\n# df_train = pd.read_csv(\"train.csv\")\n# df_test = pd.read_csv(\"test.csv\")","metadata":{"colab":{"background_save":true,"referenced_widgets":["e09ce08dd5ad4057b5c091b6a542ec80","4bb72be1601a4f03b4616fcfd7642bf7","4c6026dbbc304f05bdfc6463d144ced5","b69bd6fd0ff747d88c420c2ebf1635a3","660acc2676f7441a9fe76d42e9a623ac","c26d3dbf28a046eb933b4275a5db2ce3","b905ecbd706240dfb57f012ec64303c0","d76986a681454a2db4e4a50e02a2d6f7"]},"id":"h7Tc5-i4zhJn","outputId":"df366541-93ae-481e-ca7f-4678071d18a7","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(len(df_train)):\n#     transcript = str(df_train['transcript'][i]).replace('#','').replace('\\n',' ')\n#     df_train['transcript'][i] = transcript","metadata":{"tags":[],"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(len(df_test)):\n#     transcript = str(df_train['transcript'][i]).replace('#','').replace('\\n',' ')\n#     df_train['transcript'][i] = transcript","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_test.to_csv(\"test2.csv\")","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n\nmax_input_length = 8192\nmax_output_length = 512","metadata":{"colab":{"background_save":true},"id":"fuQoFwiPzhok","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_data_to_model_inputs(batch):\n    # tokenize the inputs and labels\n    inputs = tokenizer(\n        batch[\"src\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_input_length,\n    )\n    outputs = tokenizer(\n        batch[\"tgt\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_output_length,\n    )\n\n    batch[\"input_ids\"] = inputs.input_ids\n    batch[\"attention_mask\"] = inputs.attention_mask\n\n    # create 0 global_attention_mask lists\n    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n    ]\n\n    # since above lists are references, the following line changes the 0 index for all samples\n    batch[\"global_attention_mask\"][0][0] = 1\n    batch[\"labels\"] = outputs.input_ids\n\n    # We have to make sure that the PAD token is ignored\n    batch[\"labels\"] = [\n        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n        for labels in batch[\"labels\"]\n    ]\n\n    return batch","metadata":{"colab":{"background_save":true},"id":"tkcdTIrYzvhj","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_json(r\"/kaggle/input/dataset/elitr_minuting_dataset1.txt\", lines=True)\ndf_train , df_val = train_test_split(data,test_size =0.2) \ndf_train = Dataset.from_pandas(df_train)\ndf_val = Dataset.from_pandas(df_val)\ndf = DatasetDict()\ndf['train'] = df_train\ndf['val'] = df_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = df_train\nval_dataset = df_val","metadata":{"colab":{"background_save":true},"id":"IQbwS2H90U6G","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 10","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_dataset.map(\n    process_data_to_model_inputs,\n    batched=True,\n    batch_size=batch_size,\n    remove_columns = ['src', 'tgt', '__index_level_0__']\n)","metadata":{"colab":{"background_save":true,"referenced_widgets":["7789ba60cc9b4c2392dc7231dc23d0d4"]},"id":"GiBdJF0k1F3G","outputId":"ce6cc769-bb76-44c2-9f28-82630e7a2d70","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset = val_dataset.map(\n    process_data_to_model_inputs,\n    batched=True,\n    batch_size=batch_size,\n    remove_columns=['src', 'tgt', '__index_level_0__']\n)","metadata":{"colab":{"background_save":true,"referenced_widgets":["9813d403917244e8af44866c39bbe038"]},"id":"Xs8plK7A17pe","outputId":"4d987f37-3b3e-4207-e65d-0900cb91ea7c","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset.set_format(\n    type=\"torch\",\n    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n)\nval_dataset.set_format(\n    type=\"torch\",\n    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n)","metadata":{"colab":{"background_save":true},"id":"IpL737yl2SBX","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers --upgrade\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM,LongformerModel","metadata":{"colab":{"background_save":true},"id":"st7cl2oa2SYi","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"led = LongformerModel.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False).to(device)","metadata":{"colab":{"background_save":true,"referenced_widgets":["1790ef1a8df8476bb4fad94b637cd534","910ae3465aa14e2298d3f8005381ee2d"]},"id":"PzSXwMoj2USk","outputId":"f8cb81b6-f361-47fd-953a-23beb0dda8c6","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set generate hyperparameters\nled.config.num_beams = 2\nled.config.max_length = 512\nled.config.min_length = 100\nled.config.length_penalty = 2.0\nled.config.early_stopping = True\nled.config.no_repeat_ngram_size = 3","metadata":{"colab":{"background_save":true},"id":"Rt6USoyv2WFJ","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric","metadata":{"colab":{"background_save":true},"id":"jUkMRxU42g0-","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rouge = load_metric(\"rouge\")","metadata":{"colab":{"background_save":true,"referenced_widgets":["401f09b0b1a049afbf69b9ac9ad47093"]},"id":"fmbkEuYF2YBa","outputId":"1ea8461e-7c96-4662-abd4-1566fe50d3dd","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n\n    rouge_output = rouge.compute(\n        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n    )[\"rouge2\"].mid\n\n    return {\n        \"rouge2_precision\": round(rouge_output.precision, 4),\n        \"rouge2_recall\": round(rouge_output.recall, 4),\n        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n    }","metadata":{"colab":{"background_save":true},"id":"70lpbnV52ZmB","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments","metadata":{"colab":{"background_save":true},"id":"FL6PRJc43HJt","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    evaluation_strategy=\"steps\",\n    per_device_train_batch_size=10,\n    per_device_eval_batch_size=5,\n    fp16=True,\n    output_dir=\"./\",\n    logging_steps=5,\n    eval_steps=10,\n    save_steps=10,\n    save_total_limit=2,\n    gradient_accumulation_steps=4,\n    num_train_epochs=2,\n)","metadata":{"colab":{"background_save":true},"id":"sfcifHaH3JYm","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=led,\n    tokenizer=tokenizer,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n)","metadata":{"colab":{"background_save":true},"id":"8X8TD0te3Ozs","outputId":"e08f6653-870d-46ea-8780-4b7dde9a42ed","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"k--I7y1R3Rm1","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model('/dialogsum/')","metadata":{"id":"t32ulVXT9Hau","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM-AMI\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM-AMI\")\n\n# Load custom dataset from CSV file\ndata =pd.read_json(r\"/kaggle/input/dataset/elitr_minuting_dataset1.txt\", lines=True)\n\n# Tokenize input and output texts\ninput_ids = tokenizer.batch_encode_plus(data[\"src\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\noutput_ids = tokenizer.batch_encode_plus(data[\"tgt\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n\n# Set up training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    predict_with_generate=True,\n    num_train_epochs=100,\n    logging_steps=1000,\n    save_steps=5000,\n    eval_steps=5000,\n    warmup_steps=500,\n    weight_decay=0.01,\n    learning_rate=2e-5,\n    logging_dir=\"./logs\",\n    overwrite_output_dir=True\n)\n\n# Set up trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=list(zip(input_ids, output_ids)),\n    eval_dataset=list(zip(input_ids, output_ids)),\n    data_collator=lambda data: {'input_ids': torch.stack([item[0] for item in data]),\n                                'attention_mask': torch.stack([item[1] for item in data]),\n                                'decoder_input_ids': torch.stack([item[0] for item in data]),\n                                'decoder_attention_mask': torch.stack([item[1] for item in data]),\n                                'labels': torch.stack([item[0] for item in data])}\n)\n\n# Train the model\ntrainer.train()\n\n# Generate summaries for test inputs\ntest_input_texts = [\"Test input 1\", \"Test input 2\", \"Test input 3\"]\ntest_input_ids = tokenizer.batch_encode_plus(test_input_texts, padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\ntest_output = model.generate(test_input_ids)\ntest_summaries = tokenizer.batch_decode(test_output, skip_special_tokens=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-14T09:19:41.438265Z","iopub.execute_input":"2023-03-14T09:19:41.439137Z","iopub.status.idle":"2023-03-14T09:25:01.054604Z","shell.execute_reply.started":"2023-03-14T09:19:41.439103Z","shell.execute_reply":"2023-03-14T09:25:01.052690Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n[percpu.cc : 552] RAW: rseq syscall failed with errno 1\n[percpu.cc : 524] RAW: Failed to initialize RSEQ VCPUs in mode 1, error = 1\n[percpu.cc : 557] RAW: rseq syscall failed with errno 1\n2023-03-14 09:19:53.410313: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n2023-03-14 09:19:53.410392: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n***** Running training *****\n  Num examples = 103\n  Num Epochs = 100\n  Instantaneous batch size per device = 4\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 1\n  Total optimization steps = 2600\n  Number of trainable parameters = 509231104\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkwagh20ite\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.11 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230314_092006-1tzts10f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/kwagh20ite/huggingface/runs/1tzts10f\" target=\"_blank\">spiced-crumble-9</a></strong> to <a href=\"https://wandb.ai/kwagh20ite/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='2600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  63/2600 04:49 < 3:20:28, 0.21 it/s, Epoch 2.38/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 47\u001b[0m\n\u001b[1;32m     34\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     35\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     36\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data])}\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Generate summaries for test inputs\u001b[39;00m\n\u001b[1;32m     50\u001b[0m test_input_texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest input 1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest input 2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest input 3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/transformers/trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1540\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1542\u001b[0m )\n\u001b[0;32m-> 1543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/transformers/trainer.py:1765\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_rng_state(resume_from_checkpoint)\n\u001b[1;32m   1764\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1765\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1766\u001b[0m \n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;66;03m# Skip past any already trained steps if resuming training\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m steps_trained_in_current_epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1769\u001b[0m         steps_trained_in_current_epoch \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/torch_xla/distributed/parallel_loader.py:34\u001b[0m, in \u001b[0;36mPerDeviceLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/torch_xla/distributed/parallel_loader.py:46\u001b[0m, in \u001b[0;36mPerDeviceLoader.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_step_batch_count \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batches_yielded:\n\u001b[1;32m     45\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batches_yielded \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 46\u001b[0m   \u001b[43mxm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmark_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batches_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/torch_xla/core/xla_model.py:763\u001b[0m, in \u001b[0;36mmark_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xu\u001b[38;5;241m.\u001b[39mgetenv_as(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXLA_EMIT_STEPLOG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    762\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch_xla.core.xla_model::mark_step\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 763\u001b[0m \u001b[43mtorch_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_XLAC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla_step_marker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_XLAC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla_get_default_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv_as\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mXLA_SYNC_WAIT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;66;03m# Only emit metrics from the first local device index, to avoid emitting the\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;66;03m# same values from different threads.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_master_ordinal():\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}